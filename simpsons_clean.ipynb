{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T22:04:03.721911Z",
     "start_time": "2021-04-21T22:04:03.286813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available!  Training on GPU ...\n"
     ]
    }
   ],
   "source": [
    "# we will verify that GPU is enabled for this notebook\n",
    "# following should print: CUDA is available!  Training on GPU ...\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "train_on_gpu = torch.cuda.is_available()\n",
    "\n",
    "if not train_on_gpu:\n",
    "    print('CUDA is not available.  Training on CPU ...')\n",
    "else:\n",
    "    print('CUDA is available!  Training on GPU ...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T22:04:05.368283Z",
     "start_time": "2021-04-21T22:04:04.517090Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "from torchvision import transforms\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "\n",
    "from matplotlib import colors, pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# в sklearn не все гладко, чтобы в colab удобно выводить картинки \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T22:04:06.719588Z",
     "start_time": "2021-04-21T22:04:06.714587Z"
    }
   },
   "outputs": [],
   "source": [
    "# разные режимы датасета \n",
    "DATA_MODES = ['train', 'val', 'test']\n",
    "# все изображения будут масштабированы к размеру 224x224 px\n",
    "RESCALE_SIZE = 224\n",
    "# работаем на видеокарте\n",
    "DEVICE = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T22:04:08.754046Z",
     "start_time": "2021-04-21T22:04:08.738043Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "# квадратизация (рисайз с паддингом, чтоб не было искажений по типу круг-овал) {будем вставлять в Compose}\n",
    "class SquarePad:\n",
    "    def __call__(self, image):\n",
    "        img = Image.open(image)\n",
    "        .decode_jpeg(img, channels = 3)\n",
    "        w, h = image.size\n",
    "        \n",
    "        max_wh = np.max([w, h])\n",
    "        hp = int((max_wh - w) / 2)\n",
    "        vp = int((max_wh - h) / 2)\n",
    "        padding = (hp, vp, hp, vp)\n",
    "        return F.pad(img, padding, 0, 'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T22:04:10.581459Z",
     "start_time": "2021-04-21T22:04:10.563456Z"
    }
   },
   "outputs": [],
   "source": [
    "# используем враппер над датасетом для удобной работы\n",
    "\n",
    "class SimpsonsDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Датасет с картинками, который паралельно подгружает их из папок\n",
    "    производит скалирование и превращение в торчевые тензоры\n",
    "    \"\"\"\n",
    "    def __init__(self, files, mode):\n",
    "        super().__init__()\n",
    "        # список файлов для загрузки\n",
    "        self.files = sorted(files)\n",
    "        # режим работы\n",
    "        self.mode = mode\n",
    "\n",
    "        if self.mode not in DATA_MODES:\n",
    "            print(f\"{self.mode} is not correct; correct modes: {DATA_MODES}\")\n",
    "            raise NameError\n",
    "\n",
    "        self.len_ = len(self.files)\n",
    "     \n",
    "        self.label_encoder = LabelEncoder()\n",
    "\n",
    "        if self.mode != 'test':\n",
    "            self.labels = [path.parent.name for path in self.files]\n",
    "            self.label_encoder.fit(self.labels)\n",
    "\n",
    "            with open('label_encoder.pkl', 'wb') as le_dump_file:\n",
    "                  pickle.dump(self.label_encoder, le_dump_file)\n",
    "                      \n",
    "    def __len__(self):\n",
    "        return self.len_\n",
    "      \n",
    "    def load_sample(self, file):\n",
    "        image = Image.open(file)\n",
    "        image.load()\n",
    "        return image\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        # для преобразования изображений в тензоры PyTorch и нормализации входа\n",
    "       # transform = transforms.Compose([\n",
    "       #     transforms.ToTensor(),\n",
    "       #     transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) \n",
    "       # ])\n",
    "        if self.mode == 'train' or self.mode =='val':\n",
    "            transform = transforms.Compose([\n",
    "                 transforms.RandomResizedCrop(224),\n",
    "                 transforms.RandomHorizontalFlip(),\n",
    "                 transforms.ToTensor(),\n",
    "                 transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "                 SquarePad()\n",
    "                 ])\n",
    "        else:\n",
    "            transform = transforms.Compose([\n",
    "                transforms.Resize(224),\n",
    "                #transforms.CenterCrop(224),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                ])\n",
    "        \n",
    "        \n",
    "        x = self.load_sample(self.files[index])\n",
    "        #x = self._prepare_sample(x)\n",
    "        #x = np.array(x / 255, dtype='float32')\n",
    "        x = transform(x)\n",
    "        if self.mode == 'test':\n",
    "            return x\n",
    "        else:\n",
    "            label = self.labels[index]\n",
    "            label_id = self.label_encoder.transform([label])\n",
    "            y = label_id.item()\n",
    "            return x, y\n",
    "        \n",
    "    def _prepare_sample(self, image):\n",
    "        image = image.resize((RESCALE_SIZE, RESCALE_SIZE))\n",
    "        return np.array(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T22:04:12.783957Z",
     "start_time": "2021-04-21T22:04:12.767954Z"
    }
   },
   "outputs": [],
   "source": [
    "def imshow(inp, title=None, plt_ax=plt, default=False):\n",
    "    \"\"\"Imshow для тензоров\"\"\"\n",
    "    inp = inp.numpy().transpose((1, 2, 0))\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    inp = std * inp + mean\n",
    "    inp = np.clip(inp, 0, 1)\n",
    "    plt_ax.imshow(inp)\n",
    "    if title is not None:\n",
    "        plt_ax.set_title(title)\n",
    "    plt_ax.grid(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T22:04:15.022462Z",
     "start_time": "2021-04-21T22:04:14.836419Z"
    }
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR = Path('journey-springfield/train/simpsons_dataset')\n",
    "TEST_DIR = Path('journey-springfield/testset/testset')\n",
    "\n",
    "train_val_files = sorted(list(TRAIN_DIR.rglob('*.jpg')))\n",
    "test_files = sorted(list(TEST_DIR.rglob('*.jpg')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T22:04:15.963673Z",
     "start_time": "2021-04-21T22:04:15.875655Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_val_labels = [path.parent.name for path in train_val_files]\n",
    "train_files, val_files = train_test_split(train_val_files, test_size=0.25, \\\n",
    "                                          stratify=train_val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T22:04:16.775858Z",
     "start_time": "2021-04-21T22:04:16.718845Z"
    }
   },
   "outputs": [],
   "source": [
    "val_dataset = SimpsonsDataset(val_files, mode='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T22:04:17.569036Z",
     "start_time": "2021-04-21T22:04:17.561035Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.SimpsonsDataset at 0x21c3db16d90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-21T22:04:19.021364Z",
     "start_time": "2021-04-21T22:04:18.129164Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Tensor' object has no attribute 'read'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\PYTORCH\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   2907\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2908\u001b[1;33m         \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2909\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnsupportedOperation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'seek'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-578e458482d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfig_x\u001b[0m \u001b[1;32min\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mrandom_characters\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muniform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mim_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mrandom_characters\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     img_label = \" \".join(map(lambda x: x.capitalize(),\\\n\u001b[0;32m      9\u001b[0m                 val_dataset.label_encoder.inverse_transform([label])[0].split('_')))\n",
      "\u001b[1;32m<ipython-input-5-26d372e06930>\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;31m#x = self._prepare_sample(x)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;31m#x = np.array(x / 255, dtype='float32')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'test'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PYTORCH\\lib\\site-packages\\torchvision\\transforms\\transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 60\u001b[1;33m             \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     61\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-4549f8e59647>\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mSquarePad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PYTORCH\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   2908\u001b[0m         \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2909\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mAttributeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnsupportedOperation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2910\u001b[1;33m         \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2911\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'read'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 9 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Посмотрим на наших героев внутри датасета.\n",
    "\n",
    "fig, ax = plt.subplots(nrows=3, ncols=3,figsize=(8, 8), \\\n",
    "                        sharey=True, sharex=True)\n",
    "for fig_x in ax.flatten():\n",
    "    random_characters = int(np.random.uniform(0,1000))\n",
    "    im_val, label = val_dataset[random_characters]\n",
    "    img_label = \" \".join(map(lambda x: x.capitalize(),\\\n",
    "                val_dataset.label_encoder.inverse_transform([label])[0].split('_')))\n",
    "    imshow(im_val.data.cpu(), \\\n",
    "          title=img_label,plt_ax=fig_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:PYTORCH]",
   "language": "python",
   "name": "conda-env-PYTORCH-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
